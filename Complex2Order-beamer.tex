% !TEX encoding = UTF-8 Unicode
% !TEX TS-program = XeLaTeX
% !TEX spellcheck = English
% !TEX pdfSinglePage



\documentclass[14pt]{beamer}
	\makeatletter
	\overfullrule1em
	\beamertemplatenavigationsymbolsempty
	\setbeamercovered{transparent}
	\setbeamersize{text margin left=3mm,text margin right=3mm}
	\def\CMH{\gdef\beamer@currentmode{handout}}
	\def\CMB{\gdef\beamer@currentmode{beamer}}
	
	\catcode`æ¿€13 \defæ¿€#1{\lccode`~`#1\lowercase{\catcode`#113\def~}}
	æ¿€è‰²#1!#2 {\definecolor{#1}{HTML}{#2}}% www.uillinois.edu/OUR/brand/color_palettes
	è‰²UIB!13294b				è‰²2728 C!0455A4			è‰²2738 C!1F4096			% blues
	è‰²427!E8E9EA				è‰²Cool Gray 6!A5A8AA		è‰²Cool Gray 1!5E6669		% neutrals
	è‰²UCO!E84A27				è‰²UIC red!D50032			è‰²UIS blue!003366		% accents
	è‰²Teal!0d605e			è‰²Gray-blue!6fafc7		è‰²Citron!bfd46d			% accents
	è‰²Dark yellow!ffd125		è‰²Salmon!ee5e5e			è‰²Periwinkle!4f6898		% accents
	\setbeamercolor{normal text}{bg=UIB,fg=white}
	\setbeamercolor{structure}{fg=UCO}
	\setbeamercolor{alerted text}{fg=Dark yellow}
	\setbeamercolor{example text}{fg=Citron}

\usepackage{xurl}
	\hypersetup{pdfsubject=Information Theory (cs.IT)}
	\hypersetup{colorlinks,linkcolor=UIC red,citecolor=Citron,urlcolor=Gray-blue}

\usepackage{mathtools}

\usepackage[warnings-off={mathtools-colon,mathtools-overbracket}]{unicode-math}
	\setmainfont{Times}
	\setsansfont{HelveticaNeue-Light}
	\setmonofont{Menlo}
	\setmathfont[sans-style=literal]{texgyrepagella-math.otf}
	
	\DeclareMathOperator*\argmax{argmax}
	\DeclareMathOperator*\mybest{do-my-best}
	\DeclareMathOperator*\wt{wt}
	\def\P{P_\mathrm e}
	
	\def\({\bigl(}	\def\){\bigr)}	æ¿€ï¼ˆ{\Bigl(}		æ¿€ï¼‰{\Bigr)}		
	æ¿€ï¼»{\bigl[}		æ¿€ï¼½{\bigr]}		æ¿€ã€Œ{\Bigl[}		æ¿€ã€{\Bigr]}		
	æ¿€ï½›{\bigl\{}	æ¿€ï½{\bigr\}}	æ¿€ã€{\Bigl\{}	æ¿€ã€{\Bigr\}}	
	æ¿€ã€{\lvert}		æ¿€ã€‘{\rvert}	
	
	æ¿€ã’{\log}		æ¿€ã‘{\ln}		
	æ¿€Ë†{\hat}		æ¿€Â¯{\bar}		
	æ¿€ï½œ{\mid}		æ¿€ï¼š{\colon}		æ¿€ï¼›{\mathrel;\nobreak}		
	æ¿€Ã·{\frac}		æ¿€âˆš{\sqrt}		æ¿€Â¬{\limits}		
	æ¿€â€ #1â€ {{\text{#1}}}				
	æ¿€â‹†{\raisebox{1ex}{$\star$}}
	
	\def\K#1{^{(#1)}}
	\def\W#1{W\K{#1}}
	\def\WW#1#2{(\W{#1})\K{#2}}
	\def\WWW#1#2#3{\(\WW{#1}{#2}\)\K{#3}}
	\def\V#1{V\K{#1}}
	\def\VV#1#2{(\V{#1})\K{#2}}
	\def\VVV#1#2#3{\(\VV{#1}{#2}\)\K{#3}}
	\def\G#1{G\K{#1}}
	\def\GG#1#2{\G{#1#2}}
	
	\def\pp{\pause\par}
	\advance\parskip\fill

\usepackage{tikz,tikz-cd}
	\pgfmathsetseed{24315}\let\PMP\pgfmathparse\def\PMR{\pgfmathresult}
	\let\PMS\pgfmathsetmacro\let\PMT\pgfmathtruncatemacro\let\PMD\pgfmathdeclarefunction
	% https://tex.stackexchange.com/q/420034/
	\PMD*{axis_height}0{\begingroup\pgfmathreturn.25em\endgroup}
	\PMD*{rule_thickness}0{\begingroup\pgfmathreturn.06em\endgroup}
	\tikzset{
		every picture/.style={cap=round,join=round,line width=rule_thickness},
		% https://tex.stackexchange.com/q/146908/
		alt/.code args={<#1>#2#3}{\alt<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}}},
		uncover/.style={alt=<#1>{}{opacity=.15}},
		dynamic opacity/.style={opacity=(7/8)^\d}
	}
	\def\recursivetree#1#2{
		\edef\d{#1}\edef\z{#2}
		\fill[dynamic opacity](\d,\z/32)circle(2pt);
		\ifnum\d<\depth
		\ifdim\z pt>\threshold pt
		\ifdim\z pt<\holdthres pt
			\edef\dplusplus{\the\numexpr\d+1}
			{
				\PMS\zup{\z*(256-\z)/128}
				\draw[dynamic opacity](\d,\z/32)--(\dplusplus,\zup/32);
				\recursivetree\dplusplus\zup
			}
			{
				\PMS\zdown{\z^2/128}
				\draw[dynamic opacity](\d,\z/32)--(\dplusplus,\zdown/32);
				\recursivetree\dplusplus\zdown
			}
		\fi
		\fi
		\fi
	}

\usepackage{pgfplotstable,booktabs,colortbl}
	\pgfplotsset{compat/.cd,show suggested version=false,=1.17}
	\pgfplotstableset{
		every head row/.style={before row=\toprule,after row=\midrule},
		every last row/.style={after row=\bottomrule},string type,
	}
	\def\arraystretch{1.5}

\title[Complexity \& 2-Term of Achieving Capacity]
	{Complexity and the 2nd-Order Term\\of Capacity-Achieving Codes}
\author[H-P\ Wang]{Hsin-Po WANG}
\institute{Department of Mathematics, University of Illinois at Urbana--Champaign}
\date[2020-10]{2020-10-05 CSL SINE Group Seminar}

\begin{document}

\frame\maketitle

\makeatletter\defbeamertemplate*{sidebar right}{thinbold}{
	\tikz[remember picture,overlay,x=3mm,y=\paperheight]{\footnotesize
		\PMS\olfrac{\insertoverlaynumber/(\insertframeendpage+1-\insertframestartpage)}
		\path[save path=\stare,yscale={1/max(\insertmainframenumber-1,1)}]
			(-1,0)-|(0,1-\insertframenumber)-|+(-\olfrac,1)-|cycle;
		\tikzset{banner/.pic={\node at(-.55,-.5)[rotate=-90]
			{\beamer@shorttitle~\beamer@shortdate~\beamer@shortauthor};}}
		\fill[use path=\stare,Cool Gray 1]pic[Cool Gray 6]{banner};
		\clip[use path=\stare]pic[UIB]{banner};
	}
}

%\CMH

\frame{{Noisy channel}
	The sender inputs  $Xâ‚Â³Â²=\texttt{11001001 00001111 11011010 10100010}$.
	\pp
	The channel output $Yâ‚Â³Â²=\texttt{1--01-01 ----1--- -101---0 --0--0-0}$.
}

\frame{{Noisy channel}
	Sender inputs $Xâ‚Â³Â²âˆˆğ”½_qÂ³Â²$, where $ğ”½_q$ is input alphabet.	\\
	We may assume $ğ”½_q$ is a finite field [new idea].
	
	Channel outputs $Yâ‚Â³Â²$ according to stochastic matrix
	$â„™\{Y_i=yï½œX_i=x\}=W(y|x)$ independently for each $i$.
}

\frame{{Noisy channel coding}
	The sender inputs $Xâ‚Â³Â²âˆˆâ„¬âŠŠğ”½_q^{32}$.	\\
	$â„¬$ is a block code (codebook) of block length $N=32$.
	\pp
	The channel output	$Yâ‚Â³Â²$ according to $W(y|x)$.
	\pp
	The receiver maximize the a posterior probability
	$Ë†Xâ‚Â³Â²={\alt<+(1)>{\color{alerted text.fg}\mybest}\argmax
		Â¬_{xâ‚Â³Â²âˆˆâ„¬}}â„™\{Xâ‚Â³Â²=xâ‚Â³Â²ï½œYâ‚Â³Â²\}$.
}

\frame{{Noisy channel coding theorem}
	Channel capacity $Câ‰”\supÂ¬_{\!Xâˆ¼Q\!}I(Xï¼›Y)$ (mutual information).	\\
	Block length is $N$.	\\
	Error probability is $\Pâ‰”â„™\{Ë†Xâ‚^Nâ‰ Xâ‚^N\}$.	\\
	Code rate is $Râ‰”ã’ã€â„¬ã€‘/Nã’q$	\hfill(recall that $â„¬âŠ‚ğ”½_q^N$).	
	\pp
	[Shannon 1948]
	\emph{
		One can find block code $â„¬$	\\
		such that $\Pâ†’0$ and $Râ†’C$ as $Nâ†’âˆ$.	\\
		(And $C$ is the greatest number that makes this hold.)
	}
	%%%%% add Shannon photo
}

\frame{{2nd-order term of the theorem}
	How fast do error probability $\P$ and code rate $R$
	converge to $0$ and $C$ as block length $Nâ†’âˆ$?	\\
	Characterize them as functions ``$\P(N)$'' and ``$R(N)$''.
	\pp
	When $R$ is fixed, $\Pâ‰ˆe^{-N}$, that is, $-ã’\Pâ‰ˆN$.	\\
	When $\P$ is fixed, $Râ‰ˆC-N^{-1/2}$, that is, $(C-R)^{-2}â‰ˆN$.
	\pp
	When both $R$ and $\P$ vary, $(-ã’\P)(C-R)^{-2}â‰ˆN$.
}

\frame{{2nd-order term analysis}
	This is two-sided bound:	\\
	A code $â„¬$ exists such that $(-ã’\P)(C-R)^{-2}â‰ˆN$.	\\
	$â„¬$ does not exist such that $(-ã’\P)(C-R)^{-2}â‰« N$.
	\pp
	Block length $N$ is your income;	\\
	invest error probability $\P$ or code rate $R$ or both.
}

æ¿€åˆ†#1#2{Ã·{#1\rule{0ex}{1.5ex}}{#2\rule[-1ex]{0ex}{0ex}}}
\pgfplotstableread[col sep=ampersand]{
	P.	&	Paradigm						&	Random variable						
	LLN	&	law of large numbers			&	Â¯Xâ†’Î¼								
	LDP	&	large deviations principle		&	â„™\{Â¯X-Î¼>x\}â‰ˆe^{-nI(x)}				
	CLT	&	central limit theorem			&	Â¯X-Î¼âˆ¼ğ’©(0,Ïƒâˆšn)						
	MDP	&	moderate deviations principle	&	åˆ†{-ã’â„™\{Â¯X-Î¼>Îµ_nx\}}{Îµ_nÂ²}â‰ˆnI(x)	
}\tableTrinity
\pgfplotstableread[col sep=ampersand]{
	P.	&	Random code			&	Polar code					
	LLN	&	(\P,R)â†’(0,C)		&	(\P,R)â†’(0,C)				
	LDP	&	\Pâ‰ˆe^{-N}			&	\Pâ‰ˆe^{-N^Ï€}					
	CLT	&	C-Râ‰ˆN^{-1/2}		&	C-Râ‰ˆN^{-Ï}					
	MDP	&	åˆ†{-ã’\P}{(C-R)Â²}â‰ˆN	&	(\P,C-R)â‰ˆ(e^{-N^Ï€},N^{-Ï})	
}\tableCoding
\pgfplotstablecreatecol[create col/copy column from table=\tableCoding{Random code}]
	{Random code}\tableTrinity
\pgfplotstablecreatecol[create col/copy column from table=\tableCoding{Polar code}]
	{Polar code}\tableTrinity
\pgfplotstablemodifyeachcolumnelement{Paradigm}\of\tableTrinity\as\cell
	{\edef\cell{\noexpand\small\unexpanded\expandafter{\cell}}}
\pgfplotstablemodifyeachcolumnelement{Random variable}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Random code}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Polar code}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\frame{{2nd-order term analog}
	\centering
	\pgfplotstabletypeset[
		columns={Paradigm,Random variable},
		columns/Random variable/.style={column type={>{\onslide<2>}c}},
	]\tableTrinity
}

\frame{{2nd-order term analog}
	\centering
	\pgfplotstabletypeset[
		columns={P.,Random variable,Random code},
		columns/Random code/.style={column type={>{\onslide<2>}c}},
	]\tableTrinity
}

\frame{{However...}
	The achievability bound for random code $â„¬$	\\
	assumes exponential complexity due to $\argmaxÂ¬_{xâ‚Â³Â²âˆˆâ„¬}$.
	\pp
	Goal:
	Comparable performance,	\\
	but with a low-complexity decoder $\mybestÂ¬_{xâ‚Â³Â²âˆˆâ„¬}$.
}

\frame{{2nd-order term goal}
	\centering
	\pgfplotstabletypeset[
		columns={P.,Random code,Polar code},
		columns/Polar code/.style={
			column type={>{\onslide<2>}c},column name=Low-complexity code},
	]\tableTrinity
	
	\hfill\onslide<2>($0<Ï€,Ï$ and $Ï€+2Ï<1)$
}

\pgfplotstableread[col sep=ampersand]{
	P.		&	binary	&	prime-ary	&	finite		&	asymmetric	
	LDPâ‹†	&	k		&	k			&	k			&	k			
	MDPâ‹†	&	k		&	k			&	w			&	w			
	LDP		&	k		&	w			&	w			&	w			
	CLT		&	k		&	w			&	w			&	w			
}\tableKnown
\def\assigncontent#1{\pgfkeyssetvalue{/pgfplots/table/@cell content}{#1}}
\def\decodecontent#1#2\relax{
	\if\pgfplotstablecol0	\assigncontent{#1#2}
	\else\if#1w				\assigncontent{???}
	\else					\assigncontent{known}
	\fi\fi
}
\frame{{Polar coding}
	[ArÄ±kan 2009] invented polar coding.
	It produces practical codes with provable bounds on $\P$ and $R$.
	\pp
	\centering\pgfplotstabletypeset[
		assign cell content/.code={\decodecontent####1\relax}
	]\tableKnown
}


\frame{{Polar coding road map}
	\textcolor{example text.fg}{Channel transformation} manipulates channels.
	
	\textcolor{example text.fg}{Channel tree} is the result of recursive transformation.
	
	\textcolor{example text.fg}{Channel parameter} measuress the reliability of channels.
	
	\textcolor{example text.fg}{Channel process} is syntax candy (very useful).
	
	\textcolor{example text.fg}{Channel polarization} is a phenomenon.
}

\frame{{Channel transformation}
	Channel $W=(Xï½œY)$; input $X$; output $Y$.	\\
	Make i.i.d.\ copies $(Xâ‚ï½œYâ‚)$ and $(Xâ‚‚ï½œYâ‚‚)$.
	\pp
	$\W1â‰”(Xâ‚-Xâ‚‚ï½œYâ‚Â²)$;	\\
	$\W2â‰”(Xâ‚‚ï½œ(Xâ‚-Xâ‚‚)Yâ‚Â²)$	\hfill(juxtaposition is tupling).
}

\frame{{Channel transformation (other kernel)}
	$Uâ‚Â²$ two free variables; $G$ a $2Ã—2$ matrix (called kernel);	\\
	$Xâ‚Â²â‰”Uâ‚Â²Â·G$; channels generate $Yâ‚Â²$.
	\pp
	$\W1â‰”(Uâ‚ï½œYâ‚Â²)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚Â²)$	\hfill(juxtaposition is tupling).
}

\frame{{Channel transformation (larger kernel)}
	$Uâ‚^â„“$ this many free variables; $G$ an $â„“Ã—â„“$ kernel matrix;	\\
	$Xâ‚^â„“â‰”Uâ‚^â„“Â·G$; channels generate $Yâ‚^â„“$.
	\pp
	$\W1â‰”(Uâ‚ï½œYâ‚^â„“)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚^â„“)$;	\\
	$\W3â‰”(Uâ‚ƒï½œUâ‚Â²Yâ‚^â„“)$;	\\
	$\phantom{\W{â„“-1}}â‹®$	\\
	$\W{â„“-1}â‰”(U_â„“ï½œUâ‚^{â„“-2}Yâ‚^â„“)$;	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\pause
	\tikz[x=1em,y=-1em,overlay,shift={(5,-6)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\k in{1,...,5}{
				(-2,\k)node(U\k){$U_\k$}(U\k)-|(0,3)
				(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
				(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
			}
		;
	}
}

\frame{{Channel tree}
	Channel $W$ grows $\W1,\W2,â€¦,\Wâ„“$.
	\pp
	For each $i$, channel $\W i$ grows $\WW i1,â€¦,\WW iâ„“$.
	\pp
	For each $j$, channel $\WW ij$ grows $\WWW ij1,â€¦$.
	\pp
	\centering
	\tikz[
		grow=right,
		level/.style={
			level distance=2em*####1,sibling distance=8em/2^####1,nodes={scale=7/8}
		}
	]{
		\node{$W$}
		child foreach\i in{1,2}{
			node{$\W\i$}
			child foreach\j in{1,2}{
				node{$\WW\i\j$}
				child foreach\k in{1,2}{
					node{$\WWW\i\j\k$}
				}
			}
		}
	}
}

\frame{{Dynamic kernel [new idea*]}
	Channel $W$ grows $\W1,\W2,â€¦,\Wâ„“$ using $G$.
	\pp
	Channel $\W i$ grows $\WW i1,â€¦,\WW iâ„“$ using $\G i$.
	\pp
	Channel $\WW ij$ grows $\WWW ij1,â€¦$ using $\GG ij$.
	\pp
	\centering
	\tikz[
		grow=right,
		level/.style={
			level distance=2em*####1,
			sibling distance=8em/2^####1,
			nodes={scale=7/8}
		}
	]{
		\node{$W$}
		child foreach\i in{1,2}{
			node{$\W\i$}
			child foreach\j in{1,2}{
				node{$\WW\i\j$}
				child foreach\k in{1,2}{
					node{$\WWW\i\j\k$}
				}
			}
		}
	}
}

%	$W$ grows $\W1$.
%	$\W1$ grows $\WW11$ and $\WW12$;
%	$\W2$ grows $\WW21$ and $\WW22$.
%	$\WW11$ grows $\WWW111$ and $\WWW112$;
%	$\WW12$ grows $\WWW121$ and $\WWW122$;
%	$\WW21$ grows $\WWW211$ and $\WWW212$;
%	$\WW22$ grows $\WWW221$ and $\WWW222$.

\frame{{Channel parameter ($â„“=2$ and $n=3$)}
	Block length $N=â„“^n=2Â³=8$.
	\pp
	Select indices $â„â‰”\{212,221,222\}âˆˆ\{1,2\}Â³$.	\\
	Code rate $R=ã€â„ã€‘/N=3/8$ (nontrivial).
	\pp
	Error probability $\Pâ‰¤âˆ‘Â¬_{ijkâˆˆâ„}Hï¼ˆ\WWW ijkï¼‰$ (nontrivial);	\\
	$H(Xï½œY)$ is conditional entropy (base to be specify).
}

\frame{{It suffices to understand}
	$H(W),H(\W i),H\(\WW ij\),Hï¼ˆ\WWW ijkï¼‰,â€¦$.
	\pp
	Block length $N$ will be $â„“^â€ where we stopâ€ $.
	\pp
	Code rate $R$ will be the fraction of small $H$-values.
	\pp
	Error probability $\P$ will be $âˆ‘Â¬_â€ thoseâ€ $ small $H$-values.
}

\frame{{Channel process (syntax candy)}
	$ğ˜â‚€â‰”W$.	\\
	$ğ˜_{n+1}â‰”ğ˜_n^{(ğ˜’_{n+1})}$, where $ğ˜’_{n+1}âˆˆ\{1,2,â€¦,â„“\}$ i.i.d.\ uniform.
	\pp
	$ğ˜_nâ‰”H(ğ˜_n)$.
	\pp
	Decide depth $n$, then block length $N=â„“^n$.	\\
	Decide threshold $Î¸$, then code rate $R=â„™\{ğ˜_n<Î¸\}$.	\\
	Error probability $\P<âˆ‘â€ small â€ ğ˜_n<âˆ‘Î¸=RNÎ¸â‰¤NÎ¸$.
}

\frame{{Channel polarization}
	$ğ˜_nâ‰”H(ğ˜_n)$ is a martingale. (Invoke the Doob's.)
	$ğ˜_nâ†’ğ˜_âˆ$ a.e.\ as $nâ†’âˆ$; it turns out $ğ˜_âˆâˆˆ\{0,1\}$.
	\pp
	\tikz{
		\def\depth{6}\def\threshold{0}\def\holdthres{128}
		\recursivetree0{50}
		\pause
		\draw[alerted text.fg](\depth,1/4)--+(1,0)node[right]{threshold $Î¸$};
	}
%	\pp
%	A great question: characterize the pace of convergence.
}

\frame{{It suffices to understand}
	\par
	{\LARGE$â„™\{ğ˜_n<â€ thresholdâ€ \}>C-â€ gapâ€ $.\par}
	\pp
	Goal: $â„™ï½›ğ˜_n<e^{-â„“^{Ï€n}}ï½>C-â„“^{-Ïn}$, where $Ï€+2Ï<1$.	\\
	Then $N=â„“^n$ and $\P<Ne^{-N^Ï€}$ and $R>C-N^{-Ï}$ .
}

\frame{{Proof outline}
	\textcolor{example text.fg}{Local LDP behavior:}
	$Z(\W k)â‰¤â„“e^{qZ(W)â„“}(qZ(W))^{âŒˆk^2/3â„“âŒ‰}$.	\\
	(Never heard Bhattacharyya parameter? $Zâ‰”H$.)
	
	\textcolor{example text.fg}{Local CLT behavior:}
	$âˆ‘Â¬_{k=1}^â„“f(H(\W k))<4â„“^{1/2+Î±}$,	\\%%%%%%% replace h by f
	where $Î±=ã’ã’â„“/ã’â„“$ and $f(z)â‰”\min(z,1-z)^Î±$.
	
	\textcolor{example text.fg}{Global MDP behavior:}
	$â„™ï½›ğ˜_n<e^{-â„“^{Ï€n}}ï½>C-â„“^{-Ïn}$,
	where $Ï€+2Ï<1$, given local LDP and local CLT behaviors.
}

\frame{{Local LDP behavior 1/3}
	Want to prove $Z(\W k)â‰¤â„“e^{qZ(W)â„“}(qZ(W))^{âŒˆk^2/3â„“âŒ‰}$.	\\
	Let $zâ‰”Z(W)$; want $Z(\W k)â‰¤â„“e^{qzâ„“}(qz)^{âŒˆk^2/3â„“âŒ‰}$.
	\pp
	Lemma: $Z(\W k)â‰¤âˆ‘Â¬_{u_{k+1}^â„“âˆˆğ”½_q^{â„“-k}}z^{\wt(0â‚^{k-1}1_ku_{k+1}^â„“Â·G)}$;	\\
	RHS is weight enumerator of a coset code.
	
	$\W1â‰”(Uâ‚ï½œYâ‚^â„“)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚^â„“)$;	\\
	$\phantom{\W2}â‹®$	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\tikz[x=1em,y=-1em,overlay,shift={(5,-5)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\k in{1,...,5}{
				(-2,\k)node(U\k){$U_\k$}(U\k)-|(0,3)
				(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
				(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
			}
		;
	}
}

\frame{{Local LDP behavior 2/3}
	Want $âˆ‘Â¬_{u_{k+1}^â„“}z^{\wt(0â‚^{k-1}1_ku_{k+1}^â„“Â·G)}
		â‰¤â„“e^{qzâ„“}(qz)^{âŒˆk^2/3â„“âŒ‰}$ for some $G$.
	% In fact, RHS is $â„“(1+(q-1)Z(W))^{â„“-âŒˆk^2/3â„“âŒ‰}((q-1)Z(W))^{âŒˆk^2/3â„“âŒ‰}$.	\\
	\pp
	$G$ random; $ğ”¼â€ LHSâ€ =q^{-k}(1+(q-1)z)^â„“â‰¤q^{-k}(1+qz)^â„“$.
	\pp
	Compare $(qz)^w$-coefficients:
	$q^{-k}\binomâ„“w$ vs $â„“Ã·{â„“^{w-âŒˆk^2/3â„“âŒ‰}}{(w-âŒˆk^2/3â„“âŒ‰)!}$.
	\pp
	Simplify: $2^{-k}\binomâ„“{âŒˆk^2/3â„“âŒ‰}\binom{â„“-âŒˆk^2/3â„“âŒ‰}{w-âŒˆk^2/3â„“âŒ‰}$
	vs $â„“\binomâ„“{w-âŒˆk^2/3â„“âŒ‰}$.
}

\PMD{hleft}1{%
	\PMS\X{2^-#1}%
	\PMS\Y{1-\X}%
	\PMP{\X*#1-\Y*log2(\Y)}%
}
\PMD{hmiddle}1{%
	\PMS\Y{1-#1}%
	\PMP{-#1*log2(#1)-\Y*log2(\Y)}%
}
\frame{{Local LDP behavior 3/3}
	Boils down to $2^{-k}\binomâ„“{âŒˆk^2/3â„“âŒ‰}$ vs $â„“$; ignore/cancel $âŒˆâŒ‰$ and $â„“$.
	\pp
	$\binomâ„“d$ is about $2^{â„“h_2(d/â„“)}$ for $d=Î˜(â„“)$. (Large deviations!)	\\
	Hence $k$ vs $h_2(k^2/3â„“^2)$, which becomes $âˆš{3x}$ vs $h_2(x)$.
	\pp
	\tikz[scale=3]{
		\draw[domain=2:7]
			plot(2^-\x,{hleft(\x)})--(0,0)plot(1-2^-\x,{hleft(\x)})--(1,0);
		\draw[domain=1/4:3/4]plot(\x,{hmiddle(\x)});
		\draw plot[domain=0:1](\x^2/e,\x);
	}
	\hfill zoom $â†’$\hfill
	\tikz[scale=9]{
		\draw[domain=1/6:1/2]plot(\x,{hmiddle(\x)});
		\draw plot[domain=2/3:1](\x^2/e,\x);
	}
}

\frame{{Local CLT behavior 1/4}
	Want to prove $âˆ‘Â¬_{k=1}^â„“f(H(\W k))<4â„“^{1/2+Î±}$.
	\pp
	Break into segments
	$\begin{cases}
		âˆ‘_{k=H(W)+â„“^{-1/2+Î±}}^â„“<â„“^{1/2+Î±},	\\[2ex]
		âˆ‘_{k=H(W)-â„“^{-1/2+Î±}}^{H(W)+â„“^{-1/2+Î±}}<2â„“^{1/2+Î±}, \\[2ex]
		âˆ‘_{k=1}^{H(W)-â„“^{-1/2+Î±}}<â„“^{1/2+Î±}.
	\end{cases}$
	\pp
	\tikz[overlay,shift={(1,-1)}]{
		\draw(0,0)[domain=0:2.381101578]plot(\x^3/9,\x)plot(3-\x^3/9,\x);
		\fill foreach\y in{.1,.2,.3,.5,.8,1.3,2.1}{(\y^3/9,\y)circle(2pt)};
		\fill foreach\y in{.1,.2,.4,.8,1.6}{(3-\y^3/9,\y)circle(2pt)};
	}
}

\frame{{Local CLT behavior 2/4}
	Want to show $âˆ‘Â¬_{k=H(W)+â„“^{-1/2+Î±}}^â„“f(H(\W k))<â„“^{1/2+Î±}$.
	\pp
	Jensen LHS: $(â„“-m)fï¼ˆÃ·1{â„“-m}âˆ‘Â¬_{k=m+1}^â„“H(\W k)ï¼‰<â„“^{1/2+Î±}$,
	where $m=H(W)+â„“^{-1/2+Î±}-1$.
	\pp
	$\phantom{\W{â„“-2}}â‹®$	\\
	$\W{â„“-2}â‰”(U_{â„“-2}ï½œUâ‚^{â„“-3}Yâ‚^â„“)$,	\\
	$\W{â„“-1}â‰”(U_{â„“-1}ï½œUâ‚^{â„“-2}Yâ‚^â„“)$,	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\hfill$\smash{âˆ‘Â¬_{k=m+1}^â„“}=H(U_{m+1}^â„“ï½œUâ‚^mYâ‚^â„“)$.
}

\frame{{Local CLT behavior 3/4}
	$H(U_{m+1}^â„“ï½œUâ‚^mYâ‚^â„“)$ is what? ($m=H(W)+â„“^{-1/2+Î±}-1$)
	\pp
	The conditional entropy of	\\
	noisy channel coding.
	\tikz[x=1em,y=-1em,overlay,shift={(5,-3)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\k in{1,...,5}{
				(-2,\k)node(U\k)[opacity={\k<3?0:1}]{$U_\k$}(U\k)-|(0,3)
				(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
				(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
			}
		;
	}
	\pp
	Gallager has good bounds.
}

\frame{{Local CLT behavior 4/4}
	The other segment: $âˆ‘Â¬_{k=1}^{H(W)-â„“^{-1/2+Î±}}f(H(\W k))<4â„“^{1/2+Î±}$.	\\
	Jensen inequality: $mfï¼ˆÃ·1mâˆ‘Â¬_{k=1}^{m+1}H(\W k)ï¼‰<4â„“^{1/2+Î±}$.
	Chain rule: $H(Uâ‚^mï½œYâ‚^â„“)$, what is this? \uncover<+(1)->{Guess?}
	
	\visible<+(1)->{
		wiretap channel;	\\
		Hayashi has	\\
		good bounds	\\
		{}[new idea].
		\tikz[x=1em,y=-1em,overlay,shift={(10,-5)}]{
			\def\comment{\llap{\ifnum\k<3 message \else obscure \fi}}
			\draw
				(0,.5)rectangle node(G){$Â·G$}(3,5.5)
				foreach\k in{1,...,5}{
					(-2,\k)node(U\k){\comment$U_\k$}(U\k)-|(0,3)
					(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
					(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
				}
			;
		}
	}
}

\frame{{A calculus machinery [new idea]}
	local LDP behavior: $Z(\W k)â‰¤â„“e^{qZ(W)â„“}(qZ(W))^{âŒˆk^2/3â„“âŒ‰}$.	\\
	Local CLT behavior: $âˆ‘Â¬_{k=1}^â„“f(H(\W k))<4â„“^{1/2+Î±}$.
	\pp
	eigen: $ğ”¼[f(ğ˜_{n+1})ï½œğ˜â‚€,â€¦,ğ˜_n]â‰¤â„“^{-1/2+3Î±}f(ğ˜_n)$.
	\pp
	en23: $â„™ï½›ğ˜¡_n<e^{-n^{2/3}}ï½>C-â„“^{(-1/2+4Î±)n}$.
	\pp
	een13: $â„™ã€ğ˜¡_n<\exp\(-e^{n^{1/3}}\)ã€>C-â„“^{(-1/2+4Î±)n}$.
	\pp
	elpin: $â„™ï½›ğ˜¡_n<e^{-â„“^{Ï€n}}ï½>C-â„“^{-Ïn}$.
}

\frame{{Summary so far}
	For all $Ï€+2Ï<1$, there exist codes with	\\
	error probability $\P<e^{-N^Ï€}$	and code rate $R>C-N^{-Ï}$.
	\pp
	When only $2Ã—2$ kernels are allowed, at least $Ï€,Ï>0$.
	\pp
	It happens that they have complexity $O(ã’N)$ per bit.
	\pp
	Can we reduce the complexity further	\\
	(at the expense of worse performance etc)?
}

\frame{{Pruning}
	The bottom channel is good enough	\\
	before we reach our favorite $n$.
	
	\tikz{
		\path(0,0)circle(2pt)(0,4)circle(2pt);
		\def\depth{2}\def\threshold{8}\def\holdthres{128}
		\only<3>{\def\depth{3}}
		\only<4>{\def\depth{4}}
		\only<5>{\def\depth{5}}
		\only<6>{\def\depth{6}}
		\only<7>{\def\depth{7}}
		\recursivetree0{50}
		\draw[alerted text.fg](2,1/4)--+(\depth-1,0)node[right]{threshold $Î¸$};
	}
	\pp
	Why do we apply transform any further? (Ans: don't!)
}

\frame{{Pruning}
	The top channel is too bad.
	Do we expect	\\
	any of its descendants to be good enough?
	
	\tikz{
		\path(0,0)circle(2pt)(0,4)circle(2pt);
		\def\depth{3}\def\threshold{8}\def\holdthres{120}
		\only<3>{\def\depth{4}}
		\only<4>{\def\depth{5}}
		\only<5>{\def\depth{6}}
		\only<6>{\def\depth{7}}
		\only<7>{\def\depth{8}}
		\recursivetree0{50}
		\draw[example text.fg](3,4-1/4)--+(\depth-2.7,0)node[right]{threshold $1-Î¸$};
		\draw[alerted text.fg](2,1/4)--+(\depth-1,0)node[right]{threshold $Î¸$};
	}
	\pp
	We don't.
}

\frame{{Stopping time}
	Channel $ğ˜_i$ needs transformation if $Î¸<ğ˜_i<1-Î¸$.
	\pp
	Set $Î¸=N^{-10}$; assume $i>O(ã’ã’N)$, then $e^{-2^{Ï€i}}<Î¸$.
	\pp
	Then $â„™\{ğ˜_iâ‰¤Î¸\}>â„™ï½›ğ˜_iâ‰¤e^{-2^{Ï€i}}ï½â‰¥C-â„“^{-Ïi}$
	and $â„™\{1-Î¸â‰¤ğ˜_i\}>â„™ï½›1-e^{-2^{Ï€i}}â‰¤H_iï½â‰¥1-C-â„“^{-Ïi}$
	\pp
	That is, $â„™\{Î¸<ğ˜_i<1-Î¸\}â‰¤2â„“^{-Ïi}$.
}

\frame{{Geometric complexity}
	Complexity $=$ \#transformations $=âˆ‘Â¬_{i=0}^nâ„™\{Î¸<ğ˜_i<1-Î¸\}$.
	\pp
	$âˆ‘_{i=O(ã’ã’N)}^nâ„™\{Î¸<ğ˜_i<1-Î¸\}â‰¤âˆ‘2â„“^{-Ïi}=O(1)$;	\\
	$âˆ‘_{i=0}^{O(ã’ã’N)}â„™\{Î¸<ğ˜_i<1-Î¸\}â‰¤âˆ‘Â¬1=O(ã’ã’N)$.
	\pp
	Complexity is $O(ã’ã’N)$ per bit.
}

\frame{{Summary}
	\pp
	There exist codes with complexity $O(ã’ã’N)$ per bit,	\\
	error probability $\P<N^{-9}$, and code rate $R=C-N^{-Ï}$.
	\pp
	(Earlier) we have codes with complexity $O(ã’N)$ per bit,	\\
	error probability $\P<e^{-N^Ï€}$, and code rate $R>C-N^{-Ï}$.
	\pp
	Are there codes in between?
}

\frame{{Summary}
	Log-log code taken from (with Duursma)	\\
	Log-logarithmic Time Pruned Polar Coding	\\
	\url{https://arxiv.org/abs/1905.13340}.
	
	MDP code taken from (with Duursma)	\\
	Polar Codes' Simplicity, Random Codes' Durability	\\
	\url{https://arxiv.org/abs/1912.08995}.
}

\frame{{Question?}
	\inserttitlegraphic
	
	Predefined questions:	\\
	Why input alphabet is finite field? What advantage?	\\
	Definition of Bhattacharyya parameter?	\\
	References for XYZ?	\\
	What channels? Your contribution over others?	\\
	Future plan?
}

\def\appendixname{Appendix}
\appendix

\pgfplotstableread[col sep=ampersand]{
	Code			&	Error			&	Gap		&	Complex		&	Channel		
	random			&	e^{-N^Ï€}		&	N^{-Ï}	&	\exp(N)		&	DMC			
	RM				&	â†’0				&	â†’0		&	O(N^2)		&	BEC			
	LDPC			&	â†’0				&	â†’0		&	???			&	S.~BDMC		
	RA family		&	â†’0				&	â†’0		&	O(1)		&	BEC			
	{}[W. polar]	&	e^{-N^Ï€}		&	N^{-Ï}	&	O(ã’N)		&	DMC			
	old prune		&	e^{-N^{1/2}}	&	O(1)	&	Î˜(ã’N)		&	S.~BDMC		
	{}[W. prune]	&	N^{-9}			&	N^{-Ï}	&	O(ã’ã’N)		&	DMC			
}\tableComplex
\pgfplotstablemodifyeachcolumnelement{Error}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Gap}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Complex}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\frame{
	\centering\pgfplotstabletypeset\tableComplex
}

\pgfplotstableread[col sep=ampersand]{
	P.		&	binary			&	prime-ary	&	finite		&binary2	&finite2	
	LLN		&	Arikan09		&	STA09i		&	STA09i		&SRDR12		&w			
	LDPâ‹†	&	AT09			&	MT14		&	Sasoglu11	&HY13		&w			
	CLTâ‹†	&	KMTU10,MHU16	&	BGNRS18		&	w			&w			&w			
	MDPâ‹†	&	GX15,MHU16		&	BGS18		&	w			&w			&w			
	LDP		&	KSU10,HMTU13	&	w			&	w			&w			&w			
	CLT		&	FHMV18,GRY20	&	w			&	w			&w			&w			
	MDP		&	w				&	w			&	w			&w			&w			
}\tableRefarray
\def\assigncontent#1{\pgfkeyssetvalue{/pgfplots/table/@cell content}{#1}}
\def\decodecontent#1#2\relax{
	\if\pgfplotstablecol0	\assigncontent{#1#2}
	\else\if#1w				\assigncontent{[W.]}
	\else					\assigncontent{\cite{#1#2}}
	\fi\fi
}
\frame{
	\centering\pgfplotstabletypeset[
		columns/binary/.style={column type=@{\hskip3\tabcolsep}c},
		columns/binary2/.style={column name=binary,column type=@{\hskip3\tabcolsep}c},
		columns/finite2/.style={column name=finite},
		every head row/.style={
			before row=\toprule
				&\multicolumn3c{\hskip-3\tabcolsep symmetric}
				&\multicolumn2c{\hskip-1\tabcolsep asymmetric}\\,
			after row=\midrule},
		every last row/.style={after row=\bottomrule},
		assign cell content/.code={\decodecontent####1\relax}
	]\tableRefarray
}

æ¿€Â®{\color{alerted text.fg}}
\frame{{Input alphabet [new idea]}
	$\begin{bmatrix}
		W(yâ‚|1)		&	W(yâ‚‚|1)		&	W(yâ‚ƒ|1)		&	â‹¯	\\
		W(yâ‚|2)		&	W(yâ‚‚|2)		&	W(yâ‚ƒ|2)		&	â‹¯	\\
		W(yâ‚|3)		&	W(yâ‚‚|3)		&	W(yâ‚ƒ|3)		&	â‹¯	\\
		W(yâ‚|4)		&	W(yâ‚‚|4)		&	W(yâ‚ƒ|4)		&	â‹¯	\\
		W(yâ‚|5)		&	W(yâ‚‚|5)		&	W(yâ‚ƒ|5)		&	â‹¯	\\
		W(yâ‚|6)		&	W(yâ‚‚|6)		&	W(yâ‚ƒ|6)		&	â‹¯	\\
		Â®W(yâ‚|6)	&	Â®W(yâ‚‚|6)	&	Â®W(yâ‚ƒ|6)	&	Â®â‹¯	\\
	\end{bmatrix}$
	\hfill
	\tikz[x=4em,y=-1em,baseline=-4em]{
		\draw[line width=1em+2*rule_thickness,postaction={draw=bg,line width=1em}]
			(-1,1)--(-1,7)(0,1)--(0,6)(1,1)--(1,6);
		\fill
			foreach\y in{1,...,7}{(-1,\y)circle(2pt)}
			foreach\y in{1,...,6}{(0,\y)circle(2pt)}
			foreach\y in{1,...,6}{(1,\y)circle(2pt)}
		;
		\draw[shorten <=3pt,shorten >=3pt]
			foreach\y in{1,...,6}{(-1,\y)edge[->](0,\y)}
			(-1,7)edge[->,alerted text.fg](0,6)
			foreach\y in{1,...,6}{
				(0,\y)edge[->](1,1+rnd*5)edge[->](1,1+rnd*5)edge[->](1,1+rnd*5)
			}
		;
	}
}

\frame{{Asymmetric channels \cite{HY13}}
	Recall $U_i$ is the coordinate as in $Xâ‚^â„“â‰”Uâ‚^â„“Â·G$.	\\
	The difficulty of asymmetric channels is nonuniform $U_i$.
	
	Define synthetic channelÂ $\V kâ‰”(U_iï½œU_1^{i-1})$.	\\
	Define $\V i,\VV ij,\VVV ijk,â€¦$; define $\{ğ˜_n\}$.	\\
	It polarizes, and at the same pace.
	
	High $H(ğ˜_n)$ low $H(ğ˜_n)$ vs both high vs both low.
}

\frame{{Bhattacharyya parameter}
	Binary $Z(W)â‰”âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(y|0)W(y|1)}$.
	
	Non-binary
	$Ã·1{q-1}âˆ‘Â¬_{\substack{x,x'âˆˆğ”½_q\\xâ‰ x'}}âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(x,y)W(x',y)}$. \\
	{}[New idea] $\maxÂ¬_{0â‰ dâˆˆğ”½_q}âˆ‘Â¬_{xâˆˆğ”½_q}âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(x,y)W(x+d,y)}.$
}

\frame{{Random codes references}
	LDP: \cite{Fano61,Gallager65,SGB67,Gallager68,Gallager73,Blahut74,BF02,FLM11,DZF16}
	
	CLT: \cite{Wolfowitz57,Weiss60,Dobrushin61,Strassen62,BKB04,Hayashi09,PPV10}
	
	MDP: \cite{AW10,PV10,AW14,Arikan15p,HT15}
}

%%%% Bi-HÃ¶lder toll

\tiny
\advance\lineskip0ptplus1em
\advance\baselineskip0ptplus1em
\setbeamertemplate{bibliography item}[text]
\setbeamertemplate{bibliography entry author}{\bgroup}
\setbeamercolor{bibliography entry location}{fg=alerted text.fg}
\setbeamertemplate{bibliography entry note}{\egroup}
\bibliographystyle{plainurl}
\bibliography{Complex2Order-1}

\end{document}



